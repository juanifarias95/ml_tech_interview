1. A baseline model was built achieving the next metrics:

TRAIN
=====
==========
AUC = 0.9156
==========

TEST
====
==========
AUC = 0.9161
==========

2. The choosen metric was AUC.
   I consider both classes detection are equally important for this problem.
3. First of all, ACCURACY was not choosen, not because it is not a good metric but it is not a good
   metric to deal with imbalanced classes. Also neither PRECISION nor RECALL, because in addition to being
   imbalanced the dataset, the positive class is larger so we should probably use the ROC AUC metric because 
   the precision and recall would reflect mostly the ability of prediction of the positive class and not the 
   negative class which will naturally be harder to detect due to the smaller number of samples.
4. Now talking about AUC results, we can conclude for this first part (baseline) that model has a very good performance.
   So this is an excelent first approach.
   Something remarkable is that TEST AUC is a little bit higher than TRAIN AUC. This can be easily attributed to a random variation
5. Posible improvements:
    - Balance the classes, either with downsampling or upsampling.
    - Make a grid search over model params.
    - More Feature engineer.
    - More Data exploration to see relationship between features and understand in a better way the dataset.